# Enhancing Wireless Sound Control Through Hand Gestures

A Python-based mini project that enables users to control the sound level of a system using simple hand gestures. Developed as part of the B.E. Computer Science curriculum at MVJ College of Engineering, this project explores the application of computer vision and gesture recognition for human-computer interaction.

## Overview

This project captures real-time video from a webcam and detects hand gestures to adjust the system's sound volume. The system calculates the distance between the thumb and index finger and maps it to sound levels using Python, OpenCV, and media pipe libraries. It aims to provide a more intuitive, touchless way to control audio, useful especially for accessibility or multitasking environments.

## Technologies Used

- Python  
- OpenCV  
- MediaPipe  
- NumPy  
- PyAudio

## Key Features

- Real-time hand gesture detection and processing  
- Dynamic volume control based on finger distance  
- Cross-platform compatibility  
- Simple and intuitive interface  
- Error handling for unrecognized gestures

## Future Scope

- Add support for more advanced gestures (e.g., finger shapes, movements)  
- Integrate with other inputs like voice commands or touch screens  
- Use neural networks for improved recognition accuracy  
- Deploy as a standalone desktop application or browser-based tool  
- Assistive tech use for people with limited mobility
